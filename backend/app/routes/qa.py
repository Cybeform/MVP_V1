"""
Routes pour le syst√®me de Question-Answering (Q&A)
Permet de poser des questions sur les documents et obtenir des r√©ponses bas√©es sur les embeddings
"""

import os
from typing import Optional
from fastapi import APIRouter, Depends, HTTPException, Query
from sqlalchemy.orm import Session
from .. import models, schemas, auth
from ..database import get_db
from ..qa_system import ask_question, validate_qa_request, qa_engine
from ..embedding_jobs import check_embedding_requirements
from ..cache_service import redis_cache

router = APIRouter(prefix="/qa", tags=["Question-Answering"])

@router.get("/test")
async def test_qa_endpoint():
    """Endpoint de test pour v√©rifier que les routes Q&A fonctionnent"""
    return {"message": "‚úÖ Les routes Q&A fonctionnent correctement", "status": "ok"}

def save_qa_to_history(
    db: Session,
    user_id: int,
    document_id: int,
    question: str,
    qa_response: schemas.QAResponse
):
    """Sauvegarde une question-r√©ponse dans l'historique"""
    try:
        qa_history = models.QAHistory(
            user_id=user_id,
            document_id=document_id,
            question=question,
            answer=qa_response.answer,
            confidence=qa_response.confidence,
            processing_time_ms=qa_response.processing_time_ms,
            chunks_returned=qa_response.chunks_returned,
            similarity_threshold=qa_response.similarity_threshold,
            embedding_model=qa_response.embedding_model,
            from_cache=qa_response.from_cache
        )
        
        db.add(qa_history)
        db.commit()
        print(f"üìù Question sauvegard√©e dans l'historique: {question[:50]}...")
        
    except Exception as e:
        print(f"‚ö†Ô∏è Erreur sauvegarde historique: {e}")
        # On ne fait pas √©chouer la requ√™te si la sauvegarde √©choue
        db.rollback()

@router.post("/ask", response_model=schemas.QAResponse)
async def ask_document_question(
    qa_request: schemas.QARequest,
    similarity_threshold: Optional[float] = Query(
        default=0.6, 
        ge=0.0, 
        le=1.0, 
        description="Seuil de similarit√© minimum (0.0 √† 1.0)"
    ),
    chunks_limit: Optional[int] = Query(
        default=6, 
        ge=1, 
        le=20, 
        description="Nombre maximum de chunks √† retourner"
    ),
    model: str = Query(
        default="text-embedding-3-large", 
        description="Mod√®le d'embedding √† utiliser"
    ),
    generate_answer: bool = Query(
        default=True,
        description="G√©n√®re une r√©ponse avec GPT-4o bas√©e sur les passages trouv√©s"
    ),
    current_user: models.User = Depends(auth.get_current_active_user),
    db: Session = Depends(get_db)
):
    """
    Pose une question sur un document sp√©cifique et retourne les sections les plus pertinentes.
    
    **Syst√®me de cache activ√©:**
    - Les r√©ponses sont mises en cache pendant 24h
    - Cl√© de cache bas√©e sur: document_id + question + param√®tres
    - Am√©liore consid√©rablement les performances pour les questions r√©p√©t√©es
    
    **Historique automatique:**
    - Toutes les questions et r√©ponses sont automatiquement sauvegard√©es
    - Accessible via l'endpoint `/qa/history`
    
    **Param√®tres:**
    - `document_id`: ID du document √† analyser
    - `question`: Question √† poser sur le document
    - `similarity_threshold`: Seuil de similarit√© minimum (d√©faut: 0.6)
    - `chunks_limit`: Nombre de chunks √† retourner (d√©faut: 6)
    - `model`: Mod√®le d'embedding √† utiliser
    - `generate_answer`: Active la g√©n√©ration de r√©ponse avec GPT-4o (d√©faut: True)
    
    **Retour:**
    - Liste des chunks les plus pertinents avec leurs m√©tadonn√©es (lot, article, page)
    - Scores de similarit√© pour chaque chunk
    - R√©ponse g√©n√©r√©e par GPT-4o avec citations (si generate_answer=True)
    - Temps de traitement et statistiques
    - Flag `from_cache` pour indiquer si la r√©ponse provient du cache
    """
    
    try:
        # Param√®tres pour le cache
        cache_params = {
            "similarity_threshold": similarity_threshold,
            "chunks_limit": chunks_limit,
            "model": model,
            "generate_answer": generate_answer
        }
        
        # üéØ √âTAPE 1: V√©rifier le cache Redis
        cached_response = redis_cache.get_cached_response(
            document_id=qa_request.document_id,
            question=qa_request.question,
            **cache_params
        )
        
        if cached_response:
            # Ajouter un flag pour indiquer que la r√©ponse vient du cache
            cached_response.from_cache = True
            print(f"üéØ R√©ponse servie depuis le cache pour: {qa_request.question[:50]}...")
            
            # üìù Sauvegarder dans l'historique m√™me si c'est du cache
            save_qa_to_history(db, current_user.id, qa_request.document_id, qa_request.question, cached_response)
            
            return cached_response
        
        # üîç √âTAPE 2: Traitement normal si pas en cache
        print(f"üíª Traitement de la question (pas en cache): {qa_request.question[:50]}...")
        
        # V√©rifier les pr√©requis
        requirements = check_embedding_requirements()
        if not requirements["all_requirements_met"]:
            missing = [k for k, v in requirements.items() if not v and k != "all_requirements_met"]
            raise HTTPException(
                status_code=503,
                detail=f"Service de Q&A non disponible. Pr√©requis manquants: {', '.join(missing)}"
            )
        
        # Valider la requ√™te
        validation_errors = validate_qa_request(qa_request.document_id, qa_request.question)
        if validation_errors:
            raise HTTPException(
                status_code=400,
                detail=f"Erreurs de validation: {'; '.join(validation_errors)}"
            )
        
        # Ex√©cuter la recherche Q&A
        qa_response = await ask_question(
            document_id=qa_request.document_id,
            question=qa_request.question,
            db=db,
            user_id=current_user.id,
            similarity_threshold=similarity_threshold,
            chunks_limit=chunks_limit,
            model=model,
            generate_answer=generate_answer
        )
        
        # üíæ √âTAPE 3: Mettre en cache la r√©ponse
        qa_response.from_cache = False  # R√©ponse fra√Æchement calcul√©e
        
        cache_success = redis_cache.cache_response(
            document_id=qa_request.document_id,
            question=qa_request.question,
            qa_response=qa_response,
            **cache_params
        )
        
        if cache_success:
            print(f"üíæ R√©ponse mise en cache pour: {qa_request.question[:50]}...")
        else:
            print(f"‚ö†Ô∏è Impossible de mettre en cache la r√©ponse")
        
        # üìù √âTAPE 4: Sauvegarder dans l'historique
        save_qa_to_history(db, current_user.id, qa_request.document_id, qa_request.question, qa_response)
        
        return qa_response
        
    except ValueError as e:
        raise HTTPException(status_code=404, detail=str(e))
    except Exception as e:
        print(f"‚ùå Erreur dans ask_document_question: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Erreur lors du traitement de la question: {str(e)}"
        )

@router.get("/summary/{document_id}")
async def get_qa_summary(
    document_id: int,
    question: str = Query(..., description="Question √† poser"),
    current_user: models.User = Depends(auth.get_current_active_user),
    db: Session = Depends(get_db)
):
    """
    Retourne un r√©sum√© textuel format√© de la r√©ponse √† une question.
    Utile pour l'affichage ou l'export de r√©ponses.
    """
    
    try:
        # Cr√©er la requ√™te Q&A
        qa_request = schemas.QARequest(document_id=document_id, question=question)
        
        # Ex√©cuter la recherche
        qa_response = await ask_question(
            document_id=document_id,
            question=question,
            db=db,
            user_id=current_user.id
        )
        
        # Formater le r√©sum√©
        summary = qa_engine.format_answer_summary(qa_response)
        
        return {
            "document_id": document_id,
            "question": question,
            "chunks_found": qa_response.chunks_returned,
            "processing_time_ms": qa_response.processing_time_ms,
            "summary": summary
        }
        
    except ValueError as e:
        raise HTTPException(status_code=404, detail=str(e))
    except Exception as e:
        print(f"‚ùå Erreur dans get_qa_summary: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Erreur lors de la g√©n√©ration du r√©sum√©: {str(e)}"
        )

@router.get("/best-match/{document_id}")
async def get_best_matching_chunk(
    document_id: int,
    question: str = Query(..., description="Question √† poser"),
    current_user: models.User = Depends(auth.get_current_active_user),
    db: Session = Depends(get_db)
):
    """
    Retourne uniquement le chunk avec le meilleur score de similarit√©.
    Id√©al pour obtenir la r√©ponse la plus pertinente √† une question.
    """
    
    try:
        # Ex√©cuter la recherche (limite √† 1 chunk pour optimiser)
        qa_response = await ask_question(
            document_id=document_id,
            question=question,
            db=db,
            user_id=current_user.id,
            chunks_limit=1
        )
        
        if not qa_response.chunks:
            raise HTTPException(
                status_code=404,
                detail="Aucune section pertinente trouv√©e pour cette question"
            )
        
        best_chunk = qa_response.chunks[0]  # Premier chunk = meilleur score
        
        return {
            "document_id": document_id,
            "document_name": qa_response.document_name,
            "question": question,
            "best_match": best_chunk,
            "processing_time_ms": qa_response.processing_time_ms,
            "confidence": "haute" if best_chunk.similarity_score >= 0.8 else 
                         "moyenne" if best_chunk.similarity_score >= 0.6 else "faible"
        }
        
    except ValueError as e:
        raise HTTPException(status_code=404, detail=str(e))
    except Exception as e:
        print(f"‚ùå Erreur dans get_best_matching_chunk: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Erreur lors de la recherche du meilleur match: {str(e)}"
        )

@router.get("/stats")
def get_qa_stats(
    current_user: models.User = Depends(auth.get_current_active_user),
    db: Session = Depends(get_db)
):
    """
    Retourne les statistiques du syst√®me Q&A pour l'utilisateur.
    Inclut maintenant les statistiques du cache Redis.
    """
    
    # Compter les documents de l'utilisateur
    total_documents = db.query(models.Document).filter(
        models.Document.owner_id == current_user.id
    ).count()
    
    # Compter les chunks avec embeddings
    documents_with_chunks = db.query(models.Document).join(
        models.DocumentChunk
    ).filter(
        models.Document.owner_id == current_user.id,
        models.DocumentChunk.embedding.isnot(None)
    ).distinct().count()
    
    # Compter le total de chunks avec embeddings
    total_chunks_with_embeddings = db.query(models.DocumentChunk).join(
        models.Document
    ).filter(
        models.Document.owner_id == current_user.id,
        models.DocumentChunk.embedding.isnot(None)
    ).count()
    
    # V√©rifier les pr√©requis
    requirements = check_embedding_requirements()
    
    # Statistiques du cache Redis
    cache_stats = redis_cache.get_cache_stats()
    
    return {
        "user_documents": total_documents,
        "documents_ready_for_qa": documents_with_chunks,
        "total_searchable_chunks": total_chunks_with_embeddings,
        "qa_ready_percentage": round(
            (documents_with_chunks / total_documents * 100) if total_documents > 0 else 0, 
            1
        ),
        "system_requirements": requirements,
        "cache_system": cache_stats,
        "default_settings": {
            "similarity_threshold": qa_engine.default_similarity_threshold,
            "chunks_limit": qa_engine.default_chunks_limit,
            "max_text_length": qa_engine.max_text_length,
            "cache_ttl_hours": 24
        }
    }

# ============ NOUVEAUX ENDPOINTS POUR LA GESTION DU CACHE ============

@router.get("/cache/stats")
def get_cache_stats(
    current_user: models.User = Depends(auth.get_current_active_user)
):
    """
    Retourne les statistiques d√©taill√©es du cache Redis Q&A
    """
    return redis_cache.get_cache_stats()

@router.delete("/cache/document/{document_id}")
def invalidate_document_cache(
    document_id: int,
    current_user: models.User = Depends(auth.get_current_active_user),
    db: Session = Depends(get_db)
):
    """
    Invalide toutes les entr√©es de cache pour un document sp√©cifique
    Utile apr√®s modification ou mise √† jour d'un document
    """
    
    # V√©rifier que l'utilisateur poss√®de le document
    document = db.query(models.Document).filter(
        models.Document.id == document_id,
        models.Document.owner_id == current_user.id
    ).first()
    
    if not document:
        raise HTTPException(status_code=404, detail="Document non trouv√©")
    
    deleted_count = redis_cache.invalidate_document_cache(document_id)
    
    return {
        "message": f"Cache invalid√© pour le document {document_id}",
        "document_name": document.original_filename,
        "entries_deleted": deleted_count
    }

@router.delete("/cache/clear")
def clear_qa_cache(
    current_user: models.User = Depends(auth.get_current_active_user)
):
    """
    Efface tout le cache Q&A (utile pour le debug ou maintenance)
    ‚ö†Ô∏è Attention: cette action est irr√©versible
    """
    deleted_count = redis_cache.clear_all_qa_cache()
    
    return {
        "message": "Cache Q&A enti√®rement vid√©",
        "entries_deleted": deleted_count,
        "warning": "Toutes les r√©ponses en cache ont √©t√© supprim√©es"
    }

# ============ NOUVEAUX ENDPOINTS POUR L'HISTORIQUE Q&A ============

@router.get("/history", response_model=schemas.QAHistoryResponse)
def get_qa_history(
    page: int = Query(default=1, ge=1, description="Num√©ro de page"),
    per_page: int = Query(default=20, ge=1, le=100, description="Nombre d'entr√©es par page"),
    document_id: Optional[int] = Query(default=None, description="Filtrer par document"),
    search: Optional[str] = Query(default=None, description="Rechercher dans les questions"),
    current_user: models.User = Depends(auth.get_current_active_user),
    db: Session = Depends(get_db)
):
    """
    R√©cup√®re l'historique des questions-r√©ponses de l'utilisateur avec pagination
    
    **Param√®tres:**
    - `page`: Num√©ro de page (d√©faut: 1)
    - `per_page`: Nombre d'entr√©es par page (d√©faut: 20, max: 100)
    - `document_id`: Filtrer par document sp√©cifique (optionnel)
    - `search`: Rechercher dans les questions (optionnel)
    
    **Retour:**
    - Liste pagin√©e de l'historique Q&A avec m√©tadonn√©es de pagination
    """
    
    # Construction de la requ√™te de base
    query = db.query(
        models.QAHistory,
        models.Document.original_filename.label('document_name')
    ).join(
        models.Document
    ).filter(
        models.QAHistory.user_id == current_user.id
    )
    
    # Filtrage par document
    if document_id:
        # V√©rifier que l'utilisateur poss√®de le document
        document = db.query(models.Document).filter(
            models.Document.id == document_id,
            models.Document.owner_id == current_user.id
        ).first()
        
        if not document:
            raise HTTPException(status_code=404, detail="Document non trouv√©")
        
        query = query.filter(models.QAHistory.document_id == document_id)
    
    # Recherche dans les questions
    if search:
        search_term = f"%{search.strip()}%"
        query = query.filter(models.QAHistory.question.ilike(search_term))
    
    # Compter le total d'entr√©es
    total_entries = query.count()
    
    # Calculer la pagination
    total_pages = (total_entries + per_page - 1) // per_page
    offset = (page - 1) * per_page
    
    # R√©cup√©rer les r√©sultats pagin√©s
    results = query.order_by(
        models.QAHistory.created_at.desc()
    ).offset(offset).limit(per_page).all()
    
    # Formater les r√©sultats
    history_items = []
    for qa_history, document_name in results:
        history_item = schemas.QAHistory(
            id=qa_history.id,
            user_id=qa_history.user_id,
            document_id=qa_history.document_id,
            document_name=document_name,
            question=qa_history.question,
            answer=qa_history.answer,
            confidence=qa_history.confidence,
            processing_time_ms=qa_history.processing_time_ms,
            chunks_returned=qa_history.chunks_returned,
            similarity_threshold=qa_history.similarity_threshold,
            embedding_model=qa_history.embedding_model,
            from_cache=qa_history.from_cache,
            created_at=qa_history.created_at
        )
        history_items.append(history_item)
    
    return schemas.QAHistoryResponse(
        total_entries=total_entries,
        page=page,
        per_page=per_page,
        total_pages=total_pages,
        history=history_items
    )

@router.get("/history/{history_id}", response_model=schemas.QAHistory)
def get_qa_history_item(
    history_id: int,
    current_user: models.User = Depends(auth.get_current_active_user),
    db: Session = Depends(get_db)
):
    """
    R√©cup√®re une entr√©e sp√©cifique de l'historique Q&A
    """
    
    result = db.query(
        models.QAHistory,
        models.Document.original_filename.label('document_name')
    ).join(
        models.Document
    ).filter(
        models.QAHistory.id == history_id,
        models.QAHistory.user_id == current_user.id
    ).first()
    
    if not result:
        raise HTTPException(status_code=404, detail="Entr√©e d'historique non trouv√©e")
    
    qa_history, document_name = result
    
    return schemas.QAHistory(
        id=qa_history.id,
        user_id=qa_history.user_id,
        document_id=qa_history.document_id,
        document_name=document_name,
        question=qa_history.question,
        answer=qa_history.answer,
        confidence=qa_history.confidence,
        processing_time_ms=qa_history.processing_time_ms,
        chunks_returned=qa_history.chunks_returned,
        similarity_threshold=qa_history.similarity_threshold,
        embedding_model=qa_history.embedding_model,
        from_cache=qa_history.from_cache,
        created_at=qa_history.created_at
    )

@router.delete("/history/{history_id}")
def delete_qa_history_item(
    history_id: int,
    current_user: models.User = Depends(auth.get_current_active_user),
    db: Session = Depends(get_db)
):
    """
    Supprime une entr√©e sp√©cifique de l'historique Q&A
    """
    
    qa_history = db.query(models.QAHistory).filter(
        models.QAHistory.id == history_id,
        models.QAHistory.user_id == current_user.id
    ).first()
    
    if not qa_history:
        raise HTTPException(status_code=404, detail="Entr√©e d'historique non trouv√©e")
    
    db.delete(qa_history)
    db.commit()
    
    return {"message": "Entr√©e d'historique supprim√©e avec succ√®s"}

@router.delete("/history")
def clear_qa_history(
    document_id: Optional[int] = Query(default=None, description="Supprimer seulement pour ce document"),
    current_user: models.User = Depends(auth.get_current_active_user),
    db: Session = Depends(get_db)
):
    """
    Supprime l'historique Q&A de l'utilisateur
    
    **Param√®tres:**
    - `document_id`: Si sp√©cifi√©, supprime seulement l'historique pour ce document
    
    ‚ö†Ô∏è Attention: cette action est irr√©versible
    """
    
    query = db.query(models.QAHistory).filter(
        models.QAHistory.user_id == current_user.id
    )
    
    if document_id:
        # V√©rifier que l'utilisateur poss√®de le document
        document = db.query(models.Document).filter(
            models.Document.id == document_id,
            models.Document.owner_id == current_user.id
        ).first()
        
        if not document:
            raise HTTPException(status_code=404, detail="Document non trouv√©")
        
        query = query.filter(models.QAHistory.document_id == document_id)
    
    deleted_count = query.count()
    query.delete()
    db.commit()
    
    message = f"Historique Q&A supprim√©"
    if document_id:
        message += f" pour le document {document_id}"
    
    return {
        "message": message,
        "entries_deleted": deleted_count,
        "warning": "Cette action est irr√©versible"
    }

@router.get("/history/stats")
def get_qa_history_stats(
    current_user: models.User = Depends(auth.get_current_active_user),
    db: Session = Depends(get_db)
):
    """
    Retourne les statistiques de l'historique Q&A de l'utilisateur
    """
    
    # Statistiques g√©n√©rales
    total_questions = db.query(models.QAHistory).filter(
        models.QAHistory.user_id == current_user.id
    ).count()
    
    questions_with_answers = db.query(models.QAHistory).filter(
        models.QAHistory.user_id == current_user.id,
        models.QAHistory.answer.isnot(None)
    ).count()
    
    questions_from_cache = db.query(models.QAHistory).filter(
        models.QAHistory.user_id == current_user.id,
        models.QAHistory.from_cache == True
    ).count()
    
    # R√©partition par confiance
    confidence_stats = db.query(
        models.QAHistory.confidence,
        db.func.count(models.QAHistory.id).label('count')
    ).filter(
        models.QAHistory.user_id == current_user.id,
        models.QAHistory.confidence.isnot(None)
    ).group_by(models.QAHistory.confidence).all()
    
    # Questions par document
    documents_stats = db.query(
        models.Document.original_filename,
        models.Document.id,
        db.func.count(models.QAHistory.id).label('question_count')
    ).join(
        models.QAHistory
    ).filter(
        models.QAHistory.user_id == current_user.id
    ).group_by(
        models.Document.id, models.Document.original_filename
    ).order_by(db.func.count(models.QAHistory.id).desc()).all()
    
    return {
        "total_questions": total_questions,
        "questions_with_answers": questions_with_answers,
        "questions_from_cache": questions_from_cache,
        "cache_hit_rate": round((questions_from_cache / total_questions * 100) if total_questions > 0 else 0, 1),
        "answer_rate": round((questions_with_answers / total_questions * 100) if total_questions > 0 else 0, 1),
        "confidence_distribution": [
            {"confidence": conf, "count": count} 
            for conf, count in confidence_stats
        ],
        "most_questioned_documents": [
            {
                "document_id": doc_id,
                "document_name": doc_name,
                "question_count": count
            }
            for doc_name, doc_id, count in documents_stats[:10]  # Top 10
        ]
    } 